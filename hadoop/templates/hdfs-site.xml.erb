<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--File Managed by puppet -->
<% namenode_hosts = hadoop_namenode_host.to_a -%>
<configuration>
<% if ha != "disabled" -%>
  <!-- HA Configuration -->
<% if ha == "auto" -%>
  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>ha.zookeeper.quorum</name>
    <value><%= zk %></value>
  </property>
<%   end -%>
  <property>
    <name>dfs.nameservices</name>
    <value><%= hadoop_ha_nameservice_id %></value>
  </property>
  <property>
    <name>dfs.ha.namenodes.<%= hadoop_ha_nameservice_id %></name>
    <value><%= (1..namenode_hosts.length).map { |n| "nn#{n}" }.join(",") %></value>
  </property>
<%   namenode_hosts.each_with_index do |host,idx| -%>
  <property>
    <name>dfs.namenode.rpc-address.<%= hadoop_ha_nameservice_id %>.nn<%= idx+1 %></name>
    <value><%= host %>:<%= hadoop_namenode_port %></value>
  </property>
  <property>
    <name>dfs.namenode.http-address.<%= hadoop_ha_nameservice_id %>.nn<%= idx+1 %></name>
    <value><%= host %>:50070</value>
  </property>
  <% if hadoop_security_authentication == "kerberos" -%>
  <property>
    <name>dfs.namenode.https-address.<%= hadoop_ha_nameservice_id %>.nn<%= idx+1 %></name>
    <value><%= host %>:50475</value>
  </property>
  <% end -%>
<%   end -%>
  <!--Journal nodes configuration -->
  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value><%= journal_shared_edits_dir %></value>
  </property>
  <property>
    <name>dfs.journalnode.edits.dir</name>
    <value><%= jn_data_dir %></value>
  </property>
  <property>
    <name>dfs.client.failover.proxy.provider.<%= hadoop_ha_nameservice_id %></name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property>
  <property>
    <name>dfs.ha.fencing.methods</name>
    <value>sshfence(<%= sshfence_user %>)</value>
  </property>
  <property>
    <name>dfs.ha.fencing.ssh.private-key-files</name>
    <value><%= sshfence_keypath %></value>
  </property>
<% end -%>
<% if hadoop_security_authentication == "kerberos" -%>
  <property>
    <name>dfs.block.access.token.enable</name>
    <value>true</value>
  </property>
  <!--BUG: namenode is not starting if enabled -->
  <!--property>
    <name>dfs.https.enable</name>
    <value>true</value>
  </property-->
  <!-- NameNode security config -->
  <% if ha == "disabled" -%>
  <property>
    <name>dfs.namenode.https-address</name>
    <value><%= namenode_hosts[0] %>:50475</value>
  </property>
  <% end -%>
  <property>
    <name>dfs.https.port</name>
    <value>50475</value>
  </property>
  <property>
    <name>dfs.namenode.keytab.file</name>
    <value>/etc/hdfs.keytab</value>
  </property>
  <property>
    <name>dfs.namenode.kerberos.principal</name>
    <value>hdfs/_HOST@<%= kerberos_realm %></value>
  </property>
  <property>
    <name>dfs.namenode.kerberos.https.principal</name>
    <value>host/_HOST@<%= kerberos_realm %></value>
  </property>
  <property>
    <name>dfs.web.authentication.kerberos.keytab</name>
    <value>/etc/hdfs.keytab</value>
  </property>
  <property>
    <name>dfs.web.authentication.kerberos.principal</name>
    <value>HTTP/_HOST@<%= kerberos_realm %></value>
  </property>
  <% if ha == "disabled" -%>
  <!-- Secondary NameNode security config -->
  <property>
    <name>dfs.secondary.namenode.http-address</name>
    <value><%= hadoop_secondarynamenode_host %>:0</value>
  </property>
  <property>
    <name>dfs.secondary.https.address</name>
    <value><%= hadoop_secondarynamenode_host %>:50495</value>
  </property>
  <property>
    <name>dfs.secondary.namenode.https-port</name>
    <value>50495</value>
  </property>
  <property>
    <name>dfs.secondary.namenode.keytab.file</name>
    <value>/etc/hdfs.keytab</value> <!-- path to the HDFS keytab -->
  </property>
  <property>
    <name>dfs.secondary.namenode.kerberos.principal</name>
    <value>hdfs/_HOST@<%= kerberos_realm %></value>
  </property>
  <property>
    <name>dfs.secondary.namenode.kerberos.https.principal</name>
    <value>host/_HOST@<%= kerberos_realm %></value>
  </property>
  <%   end -%>
  <!-- DataNode security config -->
  <property>
    <name>dfs.datanode.data.dir.perm</name>
    <value>700</value>
  </property>
  <property>
    <name>dfs.datanode.address</name>
    <value>0.0.0.0:1004</value>
  </property>
  <property>
    <name>dfs.datanode.http.address</name>
    <value>0.0.0.0:1006</value>
  </property>
  <property>
    <name>dfs.datanode.keytab.file</name>
    <value>/etc/hdfs.keytab</value> <!-- path to the HDFS keytab -->
  </property>
  <property>
    <name>dfs.datanode.kerberos.principal</name>
    <value>hdfs/_HOST@<%= kerberos_realm %></value>
  </property>
  <property>
    <name>dfs.datanode.kerberos.https.principal</name>
    <value>host/_HOST@<%= kerberos_realm %></value>
  </property>
<% if ha == "auto" -%>
 <!--Quoram based storage security -->
  <property>
    <name>dfs.journalnode.keytab.file</name>
    <value>/etc/hdfs.keytab</value>
  </property>
  <property>
    <name>dfs.journalnode.kerberos.principal</name>
    <value>hdfs/_HOST@<%= kerberos_realm %></value>
  </property>
  <property>
    <name>dfs.journalnode.kerberos.internal.spnego.principal</name>
    <value>HTTP/_HOST@<%= kerberos_realm %></value>
  </property>
<% end -%>
<% end -%>
  <!-- General -->
  <property>
    <name>dfs.namenode.name.dir</name>
    <value><%= namenode_data_dirs.join(",") %></value>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value><%= hdfs_data_dirs.join(",") %></value>
  </property>
<% if hdfs_support_append == "true" %>
  <property>
    <name>dfs.support.append</name>
    <value><%= hdfs_support_append %></value>
  </property>
<% end %>
<% if ha == "disabled" %>
  <property>
     <name>dfs.namenode.checkpoint.dir</name>
     <value><%= checkpoint_data_dirs.join(",") %></value>
  </property>
  <% if hadoop_security_authentication == "simple" %>
  <property>
     <name>dfs.secondary.namenode.http-address</name>
     <value><%= hadoop_secondarynamenode_host -%>:50090</value>
  </property>
  <% end %>
<% end %>
  <property>
    <name>dfs.permissions.superusergroup</name>
    <value><%= hadoop_config_dfs_permissions_supergroup -%></value>
  </property>
  <property>
    <name>dfs.datanode.max.transfer.threads</name>
    <value><%= hadoop_config_dfs_datanode_max_transfer_threads -%></value>
  </property>
  <property>
    <name>dfs.blocksize</name>
    <value><%= hadoop_config_dfs_block_size %></value>
  </property>
  <% if num_of_nodes > 1 %>
  <property>
    <name>dfs.namenode.handler.count</name>
    <value><%= [Math.log(num_of_nodes) * 20].max.round %></value>
  </property>
  <% else -%>
  <property>
    <name>dfs.namenode.handler.count</name>
    <value>10</value>
  </property>
  <% end %>
  <property>
    <name>dfs.datanode.du.reserved</name>
    <value><%= hadoop_config_dfs_datanode_du_reserved -%></value>
  </property>
  <property>
    <name>dfs.datanode.balance.bandwidthPerSec</name>
    <value><%= hadoop_config_dfs_datanode_balance_bandwidthpersec -%></value>
  </property>
  <property>
    <name>dfs.permissions.enabled</name>
    <value><%= hadoop_config_dfs_permissions_enabled -%></value>
  </property>
  <property>
    <name>dfs.namenode.safemode.threshold-pct</name>
    <value><%= hadoop_config_dfs_namenode_safemode_threshold_pct -%></value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value><%= hadoop_config_dfs_replication -%></value>
  </property>
  <property>
    <name>dfs.namenode.replication.min</name>
    <value><%= hadoop_config_dfs_namenode_replication_min -%></value>
  </property>
  <property>
    <name>dfs.namenode.safemode.extension</name>
    <value><%= hadoop_config_dfs_namenode_safemode_extension -%></value>
  </property>
  <property>
    <name>dfs.df.interval</name>
    <value><%= hadoop_config_dfs_df_interval -%></value>
  </property>
  <property>
    <name>dfs.client.block.write.retries</name>
    <value><%= hadoop_config_dfs_client_block_write_retries -%></value>
  </property>
  <% if hue == "enabled" -%>
  <!-- Hue settings -->
  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
    <description>enables webhdfs in namenode and datanodes</description>
  </property>
  <% end %>
  <% if impala == "enabled" -%>
  <property>
    <name>dfs.datanode.data.dir.perm</name>
    <value>750</value>
  </property>
  <property>
    <name>dfs.block.local-path-access.user</name>
    <value>impala</value>
  </property>
  <property>
    <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
    <value>true</value>
  </property>
  <% end %>
</configuration>