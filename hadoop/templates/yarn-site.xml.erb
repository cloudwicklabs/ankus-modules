<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- File Managed by puppet -->
<configuration>
<% if hadoop_security_authentication == "kerberos" -%>
  <!-- ResourceManager security configs -->
  <property>
    <name>yarn.resourcemanager.principal</name>
    <value>yarn/_HOST@<%= kerberos_realm %></value>
  </property>
  <property>
    <name>yarn.resourcemanager.keytab</name>
    <value>/etc/yarn.keytab</value>
  </property>
  <!-- NodeManager security configs -->
  <property>
    <name>yarn.nodemanager.principal</name>
    <value>yarn/_HOST@<%= kerberos_realm %></value>
  </property>
  <property>
    <name>yarn.nodemanager.keytab</name>
    <value>/etc/yarn.keytab</value>
  </property>
  <property>
    <name>yarn.nodemanager.container-executor.class</name>
    <value>org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor</value>
  </property>
  <property>
    <name>yarn.nodemanager.linux-container-executor.group</name>
    <value>hadoop</value>
  </property>
  <!-- MapReduce Job History Server security configs -->
  <property>
    <name>mapreduce.jobhistory.address</name>
    <value><%= hadoop_jobhistory_host %>:10020</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.keytab</name>
    <value>/etc/mapred.keytab</value>
  </property>
  <property>
    <name>mapreduce.jobhistory.principal</name>
    <value>yarn/_HOST@<%= kerberos_realm %></value>
  </property>
<% end -%>
  <property>
    <name>yarn.web-proxy.address</name>
    <value><%= hadoop_jobhistory_host %>:<%= hadoop_proxyserver_port %></value>
  </property>
  <property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value><%= hadoop_resourcemanager_host %>:<%= hadoop_resourcetracker_port %></value>
  </property>
  <property>
    <name>yarn.resourcemanager.address</name>
    <value><%= hadoop_resourcemanager_host %>:<%= hadoop_resourcemanager_port %></value>
  </property>
  <property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value><%= hadoop_resourcemanager_host %>:<%= hadoop_resourcescheduler_port %></value>
  </property>
  <property>
    <name>yarn.resourcemanager.admin.address</name>
    <value><%= hadoop_resourcemanager_host %>:<%= hadoop_resourceadmin_port %></value>
  </property>
  <property>
    <name>yarn.resourcemanager.webapp.address</name>
    <value><%= hadoop_resourcemanager_host %>:<%= hadoop_resourcewebapp_port %></value>
  </property>
  <property>
    <name>yarn.app.mapreduce.am.staging-dir</name>
    <value>/user</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce.shuffle</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
    <value>org.apache.hadoop.mapred.ShuffleHandler</value>
  </property>
  <property>
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
  </property>
  <property>
    <name>yarn.nodemanager.local-dirs</name>
    <value><%= yarn_data_dirs.join(",") %></value>
    <final>true</final>
  </property>
  <property>
    <description>Where to store container logs.</description>
    <name>yarn.nodemanager.log-dirs</name>
    <value>/var/log/hadoop-yarn/containers</value>
  </property>
  <property>
    <description>Where to aggregate logs to.</description>
    <name>yarn.nodemanager.remote-app-log-dir</name>
    <value>/var/log/hadoop-yarn/apps</value>
  </property>
  <property>
    <description>Classpath for typical applications.</description>
     <name>yarn.application.classpath</name>
     <value>
        $HADOOP_CONF_DIR,
        $HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,
        $HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,
        $HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*,
        $HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*
     </value>
  </property>
</configuration>